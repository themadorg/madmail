/*
Maddy Mail Server - Composable all-in-one email server.
Copyright Â© 2019-2020 Max Mazurov <fox.cpp@disroot.org>, Maddy Mail Server contributors

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
*/

// Package inmemqueue implements an in-memory message queue without persistent storage.
// Messages are stored in RAM and will be lost on restart.
//
// This is useful for development, testing, or environments where message
// persistence is not required.
package inmemqueue

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"io"
	"math"
	"runtime/debug"
	"runtime/trace"
	"strconv"
	"sync"
	"time"

	"github.com/emersion/go-message/textproto"
	"github.com/emersion/go-smtp"
	"github.com/themadorg/madmail/framework/buffer"
	"github.com/themadorg/madmail/framework/config"
	modconfig "github.com/themadorg/madmail/framework/config/module"
	"github.com/themadorg/madmail/framework/exterrors"
	"github.com/themadorg/madmail/framework/log"
	"github.com/themadorg/madmail/framework/module"
	"github.com/themadorg/madmail/internal/dsn"
	"github.com/themadorg/madmail/internal/msgpipeline"
	"github.com/themadorg/madmail/internal/target"
)

// partialError describes state of partially successful message delivery.
type partialError struct {
	Errs       map[string]error
	statusLock *sync.Mutex
}

func (pe *partialError) SetStatus(rcptTo string, err error) {
	log.Debugf("PartialError.SetStatus(%s, %v)", rcptTo, err)
	if err == nil {
		return
	}
	pe.statusLock.Lock()
	defer pe.statusLock.Unlock()
	pe.Errs[rcptTo] = err
}

func (pe partialError) Error() string {
	return fmt.Sprintf("delivery failed for some recipients: %v", pe.Errs)
}

// QueuedMessage represents a message in the queue
type QueuedMessage struct {
	ID       string
	MsgMeta  *module.MsgMetadata
	From     string
	To       []string
	Header   textproto.Header
	Body     []byte
	RcptErrs map[string]*smtp.SMTPError

	TriesCount   map[string]int
	FirstAttempt time.Time
	LastAttempt  time.Time

	nextDelivery time.Time
}

// MemQueue implements an in-memory message queue
type MemQueue struct {
	name             string
	hostname         string
	autogenMsgDomain string

	dsnPipeline module.DeliveryTarget
	Target      module.DeliveryTarget

	initialRetryTime time.Duration
	retryTimeScale   float64
	maxTries         int
	postInitDelay    time.Duration

	Log log.Logger

	// In-memory queue storage
	messages   map[string]*QueuedMessage
	messagesMu sync.RWMutex

	// Scheduling
	timerMu sync.Mutex
	timers  map[string]*time.Timer

	// Delivery semaphore
	deliverySemaphore chan struct{}
	deliveryWg        sync.WaitGroup

	// For shutdown
	closed   bool
	closedMu sync.RWMutex
}

func NewQueue(_, instName string, _, inlineArgs []string) (module.Module, error) {
	q := &MemQueue{
		name:             instName,
		initialRetryTime: 15 * time.Minute,
		retryTimeScale:   1.25,
		postInitDelay:    10 * time.Second,
		maxTries:         20,
		Log:              log.Logger{Name: "inmemqueue"},
		messages:         make(map[string]*QueuedMessage),
		timers:           make(map[string]*time.Timer),
	}
	return q, nil
}

func (q *MemQueue) Init(cfg *config.Map) error {
	var maxParallelism int
	cfg.Bool("debug", true, false, &q.Log.Debug)
	cfg.Int("max_tries", false, false, 20, &q.maxTries)
	cfg.Int("max_parallelism", false, false, 16, &maxParallelism)
	cfg.Custom("target", false, true, nil, modconfig.DeliveryDirective, &q.Target)
	cfg.String("hostname", true, true, "", &q.hostname)
	cfg.String("autogenerated_msg_domain", true, false, "", &q.autogenMsgDomain)
	cfg.Custom("bounce", false, false, nil, func(m *config.Map, node config.Node) (interface{}, error) {
		return msgpipeline.New(m.Globals, node.Children)
	}, &q.dsnPipeline)
	if _, err := cfg.Process(); err != nil {
		return err
	}

	if q.dsnPipeline != nil {
		if q.autogenMsgDomain == "" {
			return errors.New("inmemqueue: autogenerated_msg_domain is required if bounce {} is specified")
		}
		q.dsnPipeline.(*msgpipeline.MsgPipeline).Hostname = q.hostname
		q.dsnPipeline.(*msgpipeline.MsgPipeline).Log = log.Logger{Name: "inmemqueue/pipeline", Debug: q.Log.Debug}
	}

	q.deliverySemaphore = make(chan struct{}, maxParallelism)

	q.Log.Debugf("delivery target: %T", q.Target)
	q.Log.Printf("in-memory queue initialized (max parallelism: %d, max tries: %d)", maxParallelism, q.maxTries)

	return nil
}

func (q *MemQueue) Name() string {
	return "inmemqueue"
}

func (q *MemQueue) InstanceName() string {
	return q.name
}

func (q *MemQueue) Close() error {
	q.closedMu.Lock()
	q.closed = true
	q.closedMu.Unlock()

	// Cancel all pending timers
	q.timerMu.Lock()
	for _, timer := range q.timers {
		timer.Stop()
	}
	q.timerMu.Unlock()

	// Wait for ongoing deliveries
	q.deliveryWg.Wait()

	q.Log.Println("in-memory queue closed")
	return nil
}

func (q *MemQueue) isClosed() bool {
	q.closedMu.RLock()
	defer q.closedMu.RUnlock()
	return q.closed
}

func (q *MemQueue) scheduleDelivery(msg *QueuedMessage, delay time.Duration) {
	if q.isClosed() {
		return
	}

	q.timerMu.Lock()
	defer q.timerMu.Unlock()

	// Cancel existing timer if any
	if timer, ok := q.timers[msg.ID]; ok {
		timer.Stop()
	}

	q.timers[msg.ID] = time.AfterFunc(delay, func() {
		q.dispatch(msg.ID)
	})
}

func (q *MemQueue) dispatch(msgID string) {
	if q.isClosed() {
		return
	}

	q.messagesMu.RLock()
	msg, ok := q.messages[msgID]
	q.messagesMu.RUnlock()

	if !ok {
		return
	}

	q.Log.Debugln("starting delivery for", msgID)

	q.deliveryWg.Add(1)
	go func() {
		q.Log.Debugln("waiting on delivery semaphore for", msgID)
		q.deliverySemaphore <- struct{}{}
		defer func() {
			<-q.deliverySemaphore
			q.deliveryWg.Done()

			if err := recover(); err != nil {
				stack := debug.Stack()
				log.Printf("panic during inmemqueue dispatch %s: %v\n%s", msgID, err, stack)
			}
		}()

		q.Log.Debugln("delivery semaphore acquired for", msgID)
		q.tryDelivery(msg)
	}()
}

func toSMTPErr(err error) *smtp.SMTPError {
	if err == nil {
		return nil
	}

	res := &smtp.SMTPError{
		Code:         554,
		EnhancedCode: smtp.EnhancedCode{5, 0, 0},
		Message:      "Internal server error",
	}

	if exterrors.IsTemporaryOrUnspec(err) {
		res.Code = 451
		res.EnhancedCode = smtp.EnhancedCode{4, 0, 0}
	}

	ctxInfo := exterrors.Fields(err)
	ctxCode, ok := ctxInfo["smtp_code"].(int)
	if ok {
		res.Code = ctxCode
	}
	ctxEnchCode, ok := ctxInfo["smtp_enchcode"].(smtp.EnhancedCode)
	if ok {
		res.EnhancedCode = ctxEnchCode
	}
	ctxMsg, ok := ctxInfo["smtp_msg"].(string)
	if ok {
		res.Message = ctxMsg
	}

	if smtpErr, ok := err.(*smtp.SMTPError); ok {
		log.Printf("plain SMTP error returned, this is deprecated")
		res.Code = smtpErr.Code
		res.EnhancedCode = smtpErr.EnhancedCode
		res.Message = smtpErr.Message
	}

	return res
}

func (q *MemQueue) tryDelivery(msg *QueuedMessage) {
	dl := target.DeliveryLogger(q.Log, msg.MsgMeta)

	partialErr := q.deliver(msg)
	dl.Debugf("errors: %v", partialErr.Errs)

	smallestTriesCount := math.MaxInt

	if msg.TriesCount == nil {
		msg.TriesCount = make(map[string]int)
	}

	newRcpts := make([]string, 0, len(partialErr.Errs))
	failedRcpts := make([]string, 0, len(partialErr.Errs))

	for _, rcpt := range msg.To {
		rcptErr, ok := partialErr.Errs[rcpt]
		if !ok {
			dl.Msg("delivered", "rcpt", rcpt, "attempt", msg.TriesCount[rcpt]+1)
			continue
		}

		dl.Error("delivery attempt failed", rcptErr, "rcpt", rcpt)
		msg.RcptErrs[rcpt] = toSMTPErr(rcptErr)

		temporary := exterrors.IsTemporaryOrUnspec(rcptErr)
		if !temporary || msg.TriesCount[rcpt]+1 >= q.maxTries {
			delete(msg.TriesCount, rcpt)
			dl.Msg("not delivered, permanent error", "rcpt", rcpt)
			failedRcpts = append(failedRcpts, rcpt)
			continue
		}

		msg.TriesCount[rcpt]++
		newRcpts = append(newRcpts, rcpt)

		if count := msg.TriesCount[rcpt]; count < smallestTriesCount {
			smallestTriesCount = count
		}
	}

	// Generate DSN for permanently failed recipients
	if len(failedRcpts) != 0 {
		q.emitDSN(msg, failedRcpts)
	}

	// No recipients left to try
	if len(newRcpts) == 0 {
		q.removeMessage(msg.ID)
		return
	}

	msg.To = newRcpts
	msg.LastAttempt = time.Now()

	// Calculate next retry time
	dl.Debugf("delay: %v * %v ^ (%v - 1)", q.initialRetryTime, q.retryTimeScale, smallestTriesCount)
	scaleFactor := time.Duration(math.Pow(q.retryTimeScale, float64(smallestTriesCount-1)))
	nextTryDelay := q.initialRetryTime * scaleFactor

	dl.Msg("will retry",
		"attempts_count", msg.TriesCount,
		"next_try_delay", nextTryDelay,
		"rcpts", msg.To)

	q.scheduleDelivery(msg, nextTryDelay)
}

func (q *MemQueue) deliver(msg *QueuedMessage) partialError {
	dl := target.DeliveryLogger(q.Log, msg.MsgMeta)
	perr := partialError{
		Errs:       map[string]error{},
		statusLock: new(sync.Mutex),
	}

	msgMeta := msg.MsgMeta.DeepCopy()
	msgMeta.ID = msgMeta.ID + "-" + strconv.FormatInt(time.Now().Unix(), 16)
	dl.Debugf("using message ID = %s", msgMeta.ID)

	msgCtx, msgTask := trace.NewTask(context.Background(), "InMemQueue delivery")
	defer msgTask.End()

	mailCtx, mailTask := trace.NewTask(msgCtx, "MAIL FROM")
	delivery, err := q.Target.Start(mailCtx, msgMeta, msg.From)
	mailTask.End()
	if err != nil {
		dl.Debugf("target.Start failed: %v", err)
		for _, rcpt := range msg.To {
			perr.Errs[rcpt] = err
		}
		return perr
	}
	dl.Debugf("target.Start OK")

	var acceptedRcpts []string
	for _, rcpt := range msg.To {
		rcptCtx, rcptTask := trace.NewTask(msgCtx, "RCPT TO")
		if err := delivery.AddRcpt(rcptCtx, rcpt, smtp.RcptOptions{}); err != nil {
			dl.Debugf("delivery.AddRcpt %s failed: %v", rcpt, err)
			perr.Errs[rcpt] = err
		} else {
			dl.Debugf("delivery.AddRcpt %s OK", rcpt)
			acceptedRcpts = append(acceptedRcpts, rcpt)
		}
		rcptTask.End()
	}

	if len(acceptedRcpts) == 0 {
		dl.Debugf("delivery.Abort (no accepted recipients)")
		if err := delivery.Abort(msgCtx); err != nil {
			dl.Error("delivery.Abort failed", err)
		}
		return perr
	}

	expandToPartialErr := func(err error) {
		for _, rcpt := range acceptedRcpts {
			perr.Errs[rcpt] = err
		}
	}

	bodyCtx, bodyTask := trace.NewTask(msgCtx, "DATA")
	defer bodyTask.End()

	// Create a buffer from the stored body
	bodyBuffer := buffer.MemoryBuffer{Slice: msg.Body}

	partDelivery, ok := delivery.(module.PartialDelivery)
	if ok {
		dl.Debugf("using delivery.BodyNonAtomic")
		partDelivery.BodyNonAtomic(bodyCtx, &perr, msg.Header, bodyBuffer)
	} else {
		if err := delivery.Body(bodyCtx, msg.Header, bodyBuffer); err != nil {
			dl.Debugf("delivery.Body failed: %v", err)
			expandToPartialErr(err)
		}
		dl.Debugf("delivery.Body OK")
	}

	allFailed := true
	for _, rcpt := range acceptedRcpts {
		if perr.Errs[rcpt] == nil {
			allFailed = false
		}
	}
	if allFailed {
		dl.Debugf("delivery.Abort (all recipients failed)")
		if err := delivery.Abort(bodyCtx); err != nil {
			dl.Msg("delivery.Abort failed", err)
		}
		return perr
	}

	if err := delivery.Commit(bodyCtx); err != nil {
		dl.Debugf("delivery.Commit failed: %v", err)
		expandToPartialErr(err)
	}
	dl.Debugf("delivery.Commit OK")

	return perr
}

func (q *MemQueue) removeMessage(msgID string) {
	q.messagesMu.Lock()
	delete(q.messages, msgID)
	q.messagesMu.Unlock()

	q.timerMu.Lock()
	if timer, ok := q.timers[msgID]; ok {
		timer.Stop()
		delete(q.timers, msgID)
	}
	q.timerMu.Unlock()

	q.Log.Debugf("removed message %s from queue", msgID)
}

type queueDelivery struct {
	q    *MemQueue
	msg  *QueuedMessage
	body []byte
}

func (qd *queueDelivery) AddRcpt(ctx context.Context, rcptTo string, _ smtp.RcptOptions) error {
	qd.msg.To = append(qd.msg.To, rcptTo)
	return nil
}

func (qd *queueDelivery) Body(ctx context.Context, header textproto.Header, body buffer.Buffer) error {
	defer trace.StartRegion(ctx, "inmemqueue/Body").End()

	// Read body into memory
	reader, err := body.Open()
	if err != nil {
		return err
	}
	defer reader.Close()

	bodyBytes, err := io.ReadAll(reader)
	if err != nil {
		return err
	}

	qd.msg.Header = header
	qd.msg.Body = bodyBytes
	qd.body = bodyBytes

	return nil
}

func (qd *queueDelivery) Abort(ctx context.Context) error {
	defer trace.StartRegion(ctx, "inmemqueue/Abort").End()
	return nil
}

func (qd *queueDelivery) Commit(ctx context.Context) error {
	defer trace.StartRegion(ctx, "inmemqueue/Commit").End()

	if qd.msg == nil {
		panic("inmemqueue: double Commit")
	}

	// Store the message
	qd.q.messagesMu.Lock()
	qd.q.messages[qd.msg.ID] = qd.msg
	qd.q.messagesMu.Unlock()

	// Schedule immediate delivery
	qd.q.scheduleDelivery(qd.msg, 0)

	qd.msg = nil
	qd.body = nil
	return nil
}

func (q *MemQueue) Start(ctx context.Context, msgMeta *module.MsgMetadata, mailFrom string) (module.Delivery, error) {
	msg := &QueuedMessage{
		ID:           msgMeta.ID,
		MsgMeta:      msgMeta,
		From:         mailFrom,
		RcptErrs:     map[string]*smtp.SMTPError{},
		FirstAttempt: time.Now(),
		LastAttempt:  time.Now(),
	}
	return &queueDelivery{q: q, msg: msg}, nil
}

func (q *MemQueue) emitDSN(msg *QueuedMessage, failedRcpts []string) {
	if q.dsnPipeline == nil {
		return
	}

	if msg.MsgMeta.OriginalFrom == "" {
		return
	}

	dsnID, err := module.GenerateMsgID()
	if err != nil {
		q.Log.Error("rand.Rand error", err)
		return
	}

	dsnEnvelope := dsn.Envelope{
		MsgID: "<" + dsnID + "@" + q.autogenMsgDomain + ">",
		From:  "MAILER-DAEMON@" + q.autogenMsgDomain,
		To:    msg.MsgMeta.OriginalFrom,
	}
	mtaInfo := dsn.ReportingMTAInfo{
		ReportingMTA:    q.hostname,
		XSender:         msg.From,
		XMessageID:      msg.MsgMeta.ID,
		ArrivalDate:     msg.FirstAttempt,
		LastAttemptDate: msg.LastAttempt,
	}
	if !msg.MsgMeta.DontTraceSender && msg.MsgMeta.Conn != nil {
		mtaInfo.ReceivedFromMTA = msg.MsgMeta.Conn.Hostname
	}

	rcptInfo := make([]dsn.RecipientInfo, 0, len(msg.RcptErrs))
	for _, rcpt := range failedRcpts {
		rcptErr := msg.RcptErrs[rcpt]

		originalRcpt := msg.MsgMeta.OriginalRcpts[rcpt]
		if originalRcpt != "" {
			rcpt = originalRcpt
		}

		rcptInfo = append(rcptInfo, dsn.RecipientInfo{
			FinalRecipient: rcpt,
			Action:         dsn.ActionFailed,
			Status:         rcptErr.EnhancedCode,
			DiagnosticCode: rcptErr,
		})
	}

	var dsnBodyBlob bytes.Buffer
	dl := target.DeliveryLogger(q.Log, msg.MsgMeta)
	dsnHeader, err := dsn.GenerateDSN(msg.MsgMeta.SMTPOpts.UTF8, dsnEnvelope, mtaInfo, rcptInfo, msg.Header, &dsnBodyBlob)
	if err != nil {
		dl.Error("failed to generate fail DSN", err)
		return
	}
	dsnBody := buffer.MemoryBuffer{Slice: dsnBodyBlob.Bytes()}

	dsnMeta := &module.MsgMetadata{
		ID: dsnID,
		SMTPOpts: smtp.MailOptions{
			UTF8:       msg.MsgMeta.SMTPOpts.UTF8,
			RequireTLS: msg.MsgMeta.SMTPOpts.RequireTLS,
		},
	}
	dl.Msg("generated failed DSN", "dsn_id", dsnID)

	msgCtx, msgTask := trace.NewTask(context.Background(), "DSN Delivery")
	defer msgTask.End()

	mailCtx, mailTask := trace.NewTask(msgCtx, "MAIL FROM")
	dsnDelivery, err := q.dsnPipeline.Start(mailCtx, dsnMeta, "")
	mailTask.End()
	if err != nil {
		dl.Error("failed to enqueue DSN", err, "dsn_id", dsnID)
		return
	}

	defer func() {
		if err != nil {
			dl.Error("failed to enqueue DSN", err, "dsn_id", dsnID)
			if err := dsnDelivery.Abort(msgCtx); err != nil {
				dl.Error("failed to abort DSN delivery", err, "dsn_id", dsnID)
			}
		}
	}()

	rcptCtx, rcptTask := trace.NewTask(msgCtx, "RCPT TO")
	if err = dsnDelivery.AddRcpt(rcptCtx, msg.From, smtp.RcptOptions{}); err != nil {
		rcptTask.End()
		return
	}
	rcptTask.End()

	bodyCtx, bodyTask := trace.NewTask(msgCtx, "DATA")
	if err = dsnDelivery.Body(bodyCtx, dsnHeader, dsnBody); err != nil {
		bodyTask.End()
		return
	}
	if err = dsnDelivery.Commit(bodyCtx); err != nil {
		bodyTask.End()
		return
	}
	bodyTask.End()
}

// PurgeBySender removes all messages from a specific sender
func (q *MemQueue) PurgeBySender(from string) (int, error) {
	q.Log.Msg("purging queue by sender", "sender", from)

	q.messagesMu.Lock()
	defer q.messagesMu.Unlock()

	count := 0
	for id, msg := range q.messages {
		if msg.From == from {
			delete(q.messages, id)
			q.timerMu.Lock()
			if timer, ok := q.timers[id]; ok {
				timer.Stop()
				delete(q.timers, id)
			}
			q.timerMu.Unlock()
			count++
		}
	}

	return count, nil
}

// PurgeByRecipient removes all messages to a specific recipient
func (q *MemQueue) PurgeByRecipient(rcpt string) (int, error) {
	q.Log.Msg("purging queue by recipient", "recipient", rcpt)

	q.messagesMu.Lock()
	defer q.messagesMu.Unlock()

	count := 0
	for id, msg := range q.messages {
		for _, to := range msg.To {
			if to == rcpt {
				delete(q.messages, id)
				q.timerMu.Lock()
				if timer, ok := q.timers[id]; ok {
					timer.Stop()
					delete(q.timers, id)
				}
				q.timerMu.Unlock()
				count++
				break
			}
		}
	}

	return count, nil
}

func init() {
	module.Register("target.inmemqueue", NewQueue)
}
